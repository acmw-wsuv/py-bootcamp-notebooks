{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interacting with `.csv` files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Import packages for later use\n",
    "\n",
    "`csv` is the built-in Python library for interacting with .csv files.\n",
    "\n",
    "`os` and `shutil` are for interacting with the operating system and files.\n",
    "\n",
    "`matplotlib` will be used for some graphs towards the end. `%matplotlib inline` tells Jupyter to show the plots next to the code cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Prepare paths to datasets\n",
    "pokemon_csv_path = 'pokemon_data.csv'\n",
    "mtg_csv_path = 'mtg_data.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples\n",
    "\n",
    "### Reading .csv files\n",
    "\n",
    "#### Counting rows\n",
    "\n",
    "First let's do something simple: Count the lines in a .csv file.\n",
    "\n",
    "At the very least, we'll have to open the file.\n",
    "\n",
    "We're specifying `encoding` to not have issues with locale on Jupyter and Binder and all that.  \n",
    "We're specifying `newline` per [the documentation](https://docs.python.org/3/library/csv.html#id3):  \n",
    "> If newline='' is not specified, newlines embedded inside quoted fields will not be interpreted correctly, and on platforms that use \\r\\n linendings on write an extra \\r will be added. It should always be safe to specify newline='', since the csv module does its own (universal) newline handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pokemon_file = open(pokemon_csv_path, encoding='utf-8', newline='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The built-in way to read .csv files is using the `csv.reader()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_reader = csv.reader(pokemon_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use `csv_reader` as an iterable, and use it to count the lines in the file.\n",
    "\n",
    "Each iteration will return one line of the .csv, which will then have an array of the comma-separated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment out the line below to continue iterating through the csv\n",
    "# You'll keep seeing this throughout the example, it resets the file position\n",
    "pokemon_file.seek(0)\n",
    "\n",
    "# next(iterable) will return the next iteration of the iterable, or raising StopIteration\n",
    "# Internally, it calls the __next__() method\n",
    "first_line = next(csv_reader)\n",
    "print(first_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pokemon_file.seek(0)\n",
    "line_count = 0\n",
    "for line in csv_reader:\n",
    "    line_count += 1\n",
    "    \n",
    "line_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use a trick with `sum()` to count up the number of lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pokemon_file.seek(0)\n",
    "line_count_with_sum = sum(1 for i in csv_reader)\n",
    "line_count_with_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we should close the file handler to release the system resources.  \n",
    "(Note: You will have to rerun the code block with `open(pokemon_csv_path, ...)` to use the above code examples again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pokemon_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generalize this and be able to count lines for any .csv file, we can throw this logic into a function.\n",
    "\n",
    "We also don't want to forget using `.close()`, so we could use a context manager to open the file instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_csv_rows(path_to_csv):\n",
    "    with open(path_to_csv, encoding='utf8', newline='') as f:\n",
    "        r = csv.reader(f)\n",
    "        return sum(1 for i in r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of rows: {count_csv_rows(pokemon_csv_path)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding data in a .csv\n",
    "\n",
    "Say we want to find all the Pokemon that weigh more than 900kg.\n",
    "\n",
    "We really want:\n",
    "* A list\n",
    "* of Pokemon names (a single Pokemon is 1 row, name is a single column in that row)\n",
    "* that have >900 weight (weight is just another column in the row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pokemon_csv_path, encoding='utf-8', newline='') as f:\n",
    "    r = csv.reader(f)\n",
    "    \n",
    "    # Find the index of the column's we're interested in\n",
    "    header_line = next(r)\n",
    "    name_index = header_line.index('name')\n",
    "    weight_index = header_line.index('weight')\n",
    "    \n",
    "    names = []\n",
    "    for row in r:\n",
    "        # Need to convert value to float to compare to 900\n",
    "        if float(row[weight_index]) > 900:\n",
    "            names.append(row[name_index])\n",
    "            \n",
    "    # List comprehension equivalent to the above loop, but it's not very clear what's going on\n",
    "    # names = [row[name_index] for row in r if float(row[weight_index]) > 900]\n",
    "\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, there is a potentially better way within the `csv` library.\n",
    "\n",
    "By using a `csv.DictReader` instead, the first row will become our field names which we can then access directly for each row. Since boilerplate code has been reduced, the list comprehension that was a bit unwieldy above will fit nicely and be very readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def more_than_900_weight(filename):\n",
    "    with open(filename, encoding='utf-8', newline='') as f:\n",
    "        r = csv.DictReader(f)\n",
    "        return [row['name'] for row in r if float(row['weight']) > 900]\n",
    "\n",
    "print(more_than_900_weight(pokemon_csv_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try modifying the code above to see other information with different conditions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting all values in a column\n",
    "\n",
    "Sometimes we'd like to be able to view all values in a single column, as opposed to all values in a single row.\n",
    "\n",
    "Here's an example code block that throws in a little extra! What does `predicate` do? Why would we use it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_column(path_to_csv, column_name):\n",
    "    with open(path_to_csv, encoding='utf-8', newline='') as f:\n",
    "        r = csv.DictReader(f)\n",
    "        return [row[column_name] for row in r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mega_names = select_column(pokemon_csv_path, 'megas')\n",
    "print(mega_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a lot of values in the above result that we don't care about if we just want the names of the mega evolutions.\n",
    "\n",
    "We could filter that out, literally using the `filter()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mega_names = select_column(pokemon_csv_path, 'megas')\n",
    "mega_names = list(filter(lambda s: len(s), mega_names))\n",
    "print(mega_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While that does work, we can make it look a bit better with a list comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mega_names = select_column(pokemon_csv_path, 'megas')\n",
    "mega_names = [name for name in mega_names if len(name)]\n",
    "print(mega_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above solution processes the entire column and then cleans the data, but what if we could do that at the same time? Then we can *maaaybe* save on some computation time and memory (do some benchmarks to see if it really makes a difference for your use case and data).\n",
    " \n",
    "Let's change the `select_column()` function to allow us to only include rows that match some predicate (in our case, like a filter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_column(path_to_csv, column_name, predicate=None):\n",
    "    with open(path_to_csv, encoding='utf-8', newline='') as f:\n",
    "        r = csv.DictReader(f)\n",
    "        \n",
    "        if predicate:\n",
    "            return [row[column_name] for row in r if predicate(row)]\n",
    "        else:\n",
    "            return [row[column_name] for row in r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mega_names = select_column(pokemon_csv_path, 'megas', lambda row: len(row['megas']))\n",
    "print(mega_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doing something with the column data\n",
    "\n",
    "Let's do some more work! How about getting the average of an entire column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average(path_to_csv, column_name):\n",
    "    # We can take advantage of the select_column() function we already made\n",
    "    # The list comprehension below maps the result to a list of floats\n",
    "    values = [float(num) for num in select_column(path_to_csv, column_name)]\n",
    "    \n",
    "    return ### FILL IN THE CODE HERE TO GET THE AVERAGE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the code to return the correct value for the average. Can you do it using entirely built-in functions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up list of attributes to stay DRY (Don't Repeat Yourself)\n",
    "attributes = ['speed', 'health', 'attack', 'defense', 'height']\n",
    "\n",
    "# Units of measurement (value) associated with type \n",
    "units = {'height': 'm',\n",
    "         'weight': 'kg'}\n",
    "\n",
    "for attribute in attributes:\n",
    "    average = get_average(pokemon_csv_path, attribute)\n",
    "    \n",
    "    # Get a little more fancy by adding units to weight and height\n",
    "    post_string = units[attribute] if attribute in units else ''\n",
    "        \n",
    "    # Take note of the :.2f down here ----v   that's like plain old printf formatting!\n",
    "    print(f'Average {attribute}: {average:.2f}' + post_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find most common occurence in a column\n",
    "\n",
    "In the below example, we can take advantage of Python's great built-in libraries with the `collections.Counter` class. It will do most of the heavy lifting when we give it some iterable.\n",
    "\n",
    "Documentation for the `collections` library can be found [here](https://docs.python.org/3/library/collections.html).\n",
    "\n",
    "***WARNING***  \n",
    "*In some college classes you may be restricted from using some built-in libraries, so you should still know the basics of how these work behind the scenes. You could try implementing your own Counter class!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `attributes` we set up earlier and the built-in `Counter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for attribute in attributes:\n",
    "    counter = Counter(select_column(pokemon_csv_path, attribute))\n",
    "    \n",
    "    result, count = counter.most_common(1)[0]  # most_common() returns a list, so we take the first element\n",
    "    \n",
    "    print(f'{result} was the most common {attribute} with {count} occurances')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Included in this repo is a larger dataset on Magic The Gathering cards, let's use our counter to look at that data too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Our Magic The Gathering dataset contains information on '\n",
    "      + f'{count_csv_rows(mtg_csv_path) - 1} cards')\n",
    "\n",
    "columns_to_count = ['type', 'subtypes']\n",
    "\n",
    "for title in columns_to_count:\n",
    "    column_data = select_column(mtg_csv_path, title)\n",
    "    \n",
    "    result, count = Counter(column_data).most_common(1)[0]\n",
    "    print(f'\"{result}\" is the most common \"{title}\" with {count} occurances')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, that last result isn't very useful to us.\n",
    "\n",
    "Try changing the code above and rerun to get this result:\n",
    "\n",
    "```\n",
    "\"Aura\" was the most common \"subtypes\" with 1673 occurances\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing to .csv files\n",
    "\n",
    "### Most basic example\n",
    "\n",
    "Writing to files follows a similar convention as reading, but we have to specify `open()`'s mode parameter. The mode defaults to read mode (`'r'`) but we want to write, so we'll use `'w'`.\n",
    "\n",
    "To see all the `open()` modes, check out the [Python3 documentation](https://docs.python.org/3/library/functions.html#open)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students = ['Bob Gel Sr.', 'Bob Gel Jr.', 'Jane Doe']\n",
    "students_with_id = [(name, i) for i, name in enumerate(students)]\n",
    "\n",
    "with open('new.csv', 'w', encoding='utf-8', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(students_with_id)  # parameter is some iterable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next code blocks opens and confirms that we wrote the .csv as expected, and then deletes it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('new.csv', encoding='utf-8', newline='') as f:\n",
    "    r = csv.reader(f)\n",
    "    for row in r:\n",
    "        print(row)\n",
    "        \n",
    "os.remove('new.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying existing values\n",
    "\n",
    "Going back to a previous example, let's modify our Pokemon dataset to cap the weight at 800kg.\n",
    "\n",
    "In order to not break the earlier code blocks, we're going to first copy the dataset to a new file and operate on that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capped_pokemon_csv_path = 'pokemon_data_cap800kg.csv'\n",
    "shutil.copy(pokemon_csv_path, capped_pokemon_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take notice of the distribution in the graph below once you run the cell.\n",
    "\n",
    "**Run it again after we update the data and see the result of our handiwork.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [float(n) for n in select_column(capped_pokemon_csv_path, 'weight')]\n",
    "num_bins = 5\n",
    "plt.hist(weights, num_bins, range=(700, 1000))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading from and writing to the same file at once is a recipe for disaster, so in this example we will load the entire dataset into memory first, and then write only once you have stopped reading. However, this method will have a larger memory footprint and may not work for larger datasets.\n",
    "\n",
    "Another solution would be to first write to some temporary file, and then move that file to overwrite the original.  \n",
    "*PS. There is a built-in library* `tempfile` *for this too!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = ''\n",
    "data = []\n",
    "with open(capped_pokemon_csv_path, encoding='utf-8') as f:\n",
    "    r = csv.DictReader(f)\n",
    "    fields = r.fieldnames\n",
    "    \n",
    "    for row in r:\n",
    "        if float(row['weight']) > 800:\n",
    "            row['weight'] = 800\n",
    "        data.append(row)\n",
    "\n",
    "with open(capped_pokemon_csv_path, 'w', encoding='utf-8') as f:\n",
    "    w = csv.DictWriter(f, fields)\n",
    "    w.writeheader()\n",
    "    \n",
    "    for row in data:\n",
    "        w.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling Python Performance\n",
    "\n",
    "The code blocks below can be ran to show a \"pager\" at the bottom of the window that displays how long that block took to run.\n",
    "\n",
    "`%%prun` is some Jupyter (really IPython) magic that profiles the code block for us. You can also do the same for a single line by starting it with `%prun`.\n",
    "\n",
    "For benchmarking outside of Jupyter, look into the `timeit` library ([documentation](https://docs.python.org/3/library/timeit.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%prun -l 0\n",
    "count_csv_rows(pokemon_csv_path) # 930 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%prun -l 0\n",
    "count_csv_rows(mtg_csv_path) # 35758 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%prun -l 0\n",
    "counter = Counter(select_column(mtg_csv_path, 'type'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%prun -l 0\n",
    "subtypes = select_column(mtg_csv_path, 'subtypes')\n",
    "subtypes = [s for s in subtypes if len(s)]\n",
    "counter = Counter(subtypes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
